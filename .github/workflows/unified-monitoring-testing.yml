name: Unified Monitoring & Testing System

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Run comprehensive tests daily at 2 AM UTC
    - cron: '0 2 * * *'

env:
  NODE_VERSION: '18'
  COVERAGE_THRESHOLD: 95
  PERFORMANCE_THRESHOLD_P95: 2000
  SECURITY_CRITICAL_THRESHOLD: 0
  SUCCESS_RATE_THRESHOLD: 95

jobs:
  # Quick validation job for fast feedback
  quick-validation:
    name: Quick Validation
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        
    - name: Install dependencies
      run: npm ci
      
    - name: Lint and format check
      run: |
        npm run format-check || echo "Format check not configured"
        
    - name: Basic unit tests
      run: |
        node -e "
          import('./src/monitoring-analytics-system/testing/testing-framework.js').then(async (m) => {
            const framework = new m.TestingFramework({
              suites: { unit: { enabled: true, timeout: 30000 } },
              execution: { parallel: true, max_workers: 2 }
            });
            await framework.initialize();
            const result = await framework.runTestSuite('unit');
            process.exit(result.status === 'passed' ? 0 : 1);
          });
        "

  # Unified monitoring system validation
  monitoring-validation:
    name: Monitoring System Validation
    runs-on: ubuntu-latest
    timeout-minutes: 15
    needs: quick-validation
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        
    - name: Install dependencies
      run: npm ci
      
    - name: Validate monitoring system
      run: |
        node -e "
          import('./src/monitoring-analytics-system/core/monitoring-system.js').then(async (m) => {
            const system = new m.MonitoringAnalyticsSystem({
              enabled: true,
              dashboard: { enabled: false }, // Disable dashboard for CI
              webhooks: { enabled: false }, // Disable webhooks for CI
              notifications: { 
                email: { enabled: false }, 
                slack: { enabled: false },
                pagerduty: { enabled: false }
              }
            });
            
            console.log('üîç Initializing monitoring system...');
            // System is initialized in constructor
            
            console.log('üöÄ Starting monitoring system...');
            await system.start();
            
            console.log('üè• Running health check...');
            const health = await system.getHealthStatus();
            console.log(\`Health Status: \${health.system.status}\`);
            console.log(\`Overall Score: \${health.overall_score}/100\`);
            
            console.log('üìä Getting system metrics...');
            const metrics = system.getSystemMetrics();
            console.log(\`Components: \${metrics.components_count}\`);
            console.log(\`Running: \${metrics.is_running}\`);
            
            console.log('‚èπÔ∏è Stopping monitoring system...');
            await system.stop();
            
            if (health.system.status !== 'running' || health.overall_score < 80) {
              console.error('‚ùå Monitoring system validation failed');
              process.exit(1);
            }
            
            console.log('‚úÖ Monitoring system validation passed');
          });
        "

  # Comprehensive unit testing with coverage
  unit-tests:
    name: Unit Tests & Coverage
    runs-on: ubuntu-latest
    timeout-minutes: 20
    needs: quick-validation
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        
    - name: Install dependencies
      run: npm ci
      
    - name: Run comprehensive unit tests
      run: |
        node -e "
          import('./src/monitoring-analytics-system/testing/testing-framework.js').then(async (m) => {
            const framework = new m.TestingFramework({
              suites: { 
                unit: { 
                  enabled: true,
                  coverage_threshold: ${{ env.COVERAGE_THRESHOLD }},
                  parallel: true
                }
              },
              execution: { parallel: true, max_workers: '50%' },
              quality_gates: {
                coverage_threshold: ${{ env.COVERAGE_THRESHOLD }}
              }
            });
            await framework.initialize();
            const result = await framework.runTestSuite('unit');
            process.exit(result.status === 'passed' ? 0 : 1);
          });
        "
      
    - name: Upload coverage reports
      uses: codecov/codecov-action@v3
      with:
        file: ./tests/reports/unit_coverage.lcov
        flags: unit-tests
        name: unit-tests-coverage

  # Integration testing with services
  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    timeout-minutes: 25
    needs: quick-validation
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: test_password
          POSTGRES_USER: test_user
          POSTGRES_DB: taskmaster_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
          
      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        
    - name: Install dependencies
      run: npm ci
      
    - name: Setup test environment
      env:
        DATABASE_URL: postgresql://test_user:test_password@localhost:5432/taskmaster_test
        REDIS_URL: redis://localhost:6379
      run: |
        echo "Setting up integration test environment..."
        
    - name: Run integration tests
      env:
        DATABASE_URL: postgresql://test_user:test_password@localhost:5432/taskmaster_test
        REDIS_URL: redis://localhost:6379
        SETUP_TEST_DB: true
      run: |
        node -e "
          import('./src/monitoring-analytics-system/testing/testing-framework.js').then(async (m) => {
            const framework = new m.TestingFramework({
              suites: { integration: { enabled: true } },
              environments: { 
                test: { 
                  database_url: process.env.DATABASE_URL, 
                  redis_url: process.env.REDIS_URL 
                } 
              }
            });
            await framework.initialize();
            const result = await framework.runTestSuite('integration');
            process.exit(result.status === 'passed' ? 0 : 1);
          });
        "

  # Security testing and vulnerability scanning
  security-tests:
    name: Security Tests
    runs-on: ubuntu-latest
    timeout-minutes: 30
    needs: quick-validation
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        
    - name: Install dependencies
      run: npm ci
      
    - name: Run security tests
      run: |
        node -e "
          import('./src/monitoring-analytics-system/testing/testing-framework.js').then(async (m) => {
            const framework = new m.TestingFramework({
              suites: { 
                security: { 
                  enabled: true,
                  vulnerability_scanning: { fail_on_critical: true }
                }
              },
              quality_gates: {
                security_critical_threshold: ${{ env.SECURITY_CRITICAL_THRESHOLD }}
              }
            });
            await framework.initialize();
            const result = await framework.runTestSuite('security');
            process.exit(result.status === 'passed' ? 0 : 1);
          });
        "
      
    - name: Check security thresholds
      run: |
        if [ -f "tests/reports/security_report.json" ]; then
          CRITICAL=$(jq -r '.summary.critical' tests/reports/security_report.json)
          if [ "$CRITICAL" -gt "$SECURITY_CRITICAL_THRESHOLD" ]; then
            echo "‚ùå Security test failed: $CRITICAL critical vulnerabilities found (threshold: $SECURITY_CRITICAL_THRESHOLD)"
            exit 1
          else
            echo "‚úÖ Security test passed: $CRITICAL critical vulnerabilities (threshold: $SECURITY_CRITICAL_THRESHOLD)"
          fi
        fi

  # Performance testing and benchmarking
  performance-tests:
    name: Performance Tests
    runs-on: ubuntu-latest
    timeout-minutes: 35
    needs: [unit-tests, integration-tests]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        
    - name: Install dependencies
      run: npm ci
      
    - name: Run performance tests
      env:
        START_TEST_SERVICES: true
      run: |
        node -e "
          import('./src/monitoring-analytics-system/testing/testing-framework.js').then(async (m) => {
            const framework = new m.TestingFramework({
              suites: { 
                performance: { 
                  enabled: true,
                  load_testing: { concurrent_users: [10, 25] }
                }
              },
              quality_gates: {
                performance_threshold_p95: ${{ env.PERFORMANCE_THRESHOLD_P95 }}
              }
            });
            await framework.initialize();
            const result = await framework.runTestSuite('performance');
            process.exit(result.status === 'passed' ? 0 : 1);
          });
        "
      
    - name: Check performance thresholds
      run: |
        if [ -f "tests/reports/performance_report.json" ]; then
          P95_TIME=$(jq -r '.summary.p95_response_time' tests/reports/performance_report.json)
          if [ "$P95_TIME" -gt "$PERFORMANCE_THRESHOLD_P95" ]; then
            echo "‚ùå Performance test failed: P95 response time ${P95_TIME}ms > ${PERFORMANCE_THRESHOLD_P95}ms"
            exit 1
          else
            echo "‚úÖ Performance test passed: P95 response time ${P95_TIME}ms (threshold: ${PERFORMANCE_THRESHOLD_P95}ms)"
          fi
        fi

  # End-to-end workflow testing
  e2e-tests:
    name: End-to-End Tests
    runs-on: ubuntu-latest
    timeout-minutes: 40
    needs: [unit-tests, integration-tests]
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: test_password
          POSTGRES_USER: test_user
          POSTGRES_DB: taskmaster_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        
    - name: Install dependencies
      run: npm ci
      
    - name: Run E2E tests
      env:
        DATABASE_URL: postgresql://test_user:test_password@localhost:5432/taskmaster_test
        SETUP_TEST_DB: true
        START_TEST_SERVICES: true
      run: |
        node -e "
          import('./src/monitoring-analytics-system/testing/testing-framework.js').then(async (m) => {
            const framework = new m.TestingFramework({
              suites: { e2e: { enabled: true } },
              environments: { 
                test: { database_url: process.env.DATABASE_URL } 
              }
            });
            await framework.initialize();
            const result = await framework.runTestSuite('e2e');
            process.exit(result.status === 'passed' ? 0 : 1);
          });
        "

  # Webhook system testing
  webhook-tests:
    name: Webhook System Tests
    runs-on: ubuntu-latest
    timeout-minutes: 20
    needs: [unit-tests, integration-tests]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        
    - name: Install dependencies
      run: npm ci
      
    - name: Test webhook system
      run: |
        node -e "
          import('./src/monitoring-analytics-system/integrations/github-webhooks.js').then(async (m) => {
            const webhookHandler = new m.GitHubWebhookHandler({
              server: { port: 3001 },
              github: { 
                enabled: true,
                secret: 'test-secret',
                validation: { signature_verification: false }
              }
            });
            
            console.log('üîó Testing webhook system...');
            await webhookHandler.start();
            
            // Simulate webhook processing
            const testPayload = {
              action: 'opened',
              pull_request: {
                number: 123,
                title: 'Test PR',
                head: { ref: 'test-branch' }
              },
              repository: {
                full_name: 'test/repo'
              }
            };
            
            const result = await webhookHandler.processWebhook('pull_request', testPayload);
            console.log(\`Webhook processing result: \${result.status}\`);
            
            await webhookHandler.stop();
            
            if (result.status !== 'success') {
              console.error('‚ùå Webhook system test failed');
              process.exit(1);
            }
            
            console.log('‚úÖ Webhook system test passed');
          });
        "

  # Comprehensive test suite (only on main branch or scheduled)
  comprehensive-tests:
    name: Comprehensive Test Suite
    runs-on: ubuntu-latest
    timeout-minutes: 60
    if: github.ref == 'refs/heads/main' || github.event_name == 'schedule'
    needs: [unit-tests, integration-tests, security-tests, performance-tests, e2e-tests, webhook-tests, monitoring-validation]
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: test_password
          POSTGRES_USER: test_user
          POSTGRES_DB: taskmaster_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
          
      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        
    - name: Install dependencies
      run: npm ci
      
    - name: Run comprehensive unified test suite
      env:
        DATABASE_URL: postgresql://test_user:test_password@localhost:5432/taskmaster_test
        REDIS_URL: redis://localhost:6379
        COVERAGE_THRESHOLD: ${{ env.COVERAGE_THRESHOLD }}
        PERFORMANCE_THRESHOLD_P95: ${{ env.PERFORMANCE_THRESHOLD_P95 }}
        SECURITY_CRITICAL_THRESHOLD: ${{ env.SECURITY_CRITICAL_THRESHOLD }}
        SUCCESS_RATE_THRESHOLD: ${{ env.SUCCESS_RATE_THRESHOLD }}
      run: |
        node -e "
          import('./src/monitoring-analytics-system/testing/testing-framework.js').then(async (m) => {
            const framework = new m.TestingFramework({
              execution: { parallel: true, max_workers: '50%' },
              quality_gates: {
                coverage_threshold: process.env.COVERAGE_THRESHOLD,
                performance_threshold_p95: process.env.PERFORMANCE_THRESHOLD_P95,
                security_critical_threshold: process.env.SECURITY_CRITICAL_THRESHOLD,
                success_rate_threshold: process.env.SUCCESS_RATE_THRESHOLD
              },
              environments: {
                test: {
                  database_url: process.env.DATABASE_URL,
                  redis_url: process.env.REDIS_URL
                }
              }
            });
            await framework.initialize();
            const execution = await framework.runAllTests();
            
            console.log('üìä Comprehensive Test Results:');
            console.log(\`Total Tests: \${execution.summary.total_tests}\`);
            console.log(\`Success Rate: \${execution.summary.success_rate}%\`);
            console.log(\`Quality Gates: \${execution.quality_gates.passed ? 'PASSED' : 'FAILED'}\`);
            
            process.exit(execution.status === 'passed' && execution.quality_gates.passed ? 0 : 1);
          });
        "
      
    - name: Upload comprehensive test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: comprehensive-test-results
        path: |
          tests/reports/
          tests/logs/

  # Quality gate evaluation
  quality-gate:
    name: Quality Gate
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests, security-tests, performance-tests, e2e-tests, webhook-tests, monitoring-validation]
    if: always()
    
    steps:
    - name: Download all test artifacts
      uses: actions/download-artifact@v3
      
    - name: Quality gate evaluation
      run: |
        echo "üîç Evaluating unified quality gates..."
        
        # Check if all required jobs passed
        REQUIRED_JOBS=("unit-tests" "integration-tests" "security-tests" "performance-tests" "e2e-tests" "webhook-tests" "monitoring-validation")
        FAILED_JOBS=()
        
        for job in "${REQUIRED_JOBS[@]}"; do
          case "$job" in
            "unit-tests")
              if [ "${{ needs.unit-tests.result }}" != "success" ]; then
                FAILED_JOBS+=("$job")
              fi
              ;;
            "integration-tests")
              if [ "${{ needs.integration-tests.result }}" != "success" ]; then
                FAILED_JOBS+=("$job")
              fi
              ;;
            "security-tests")
              if [ "${{ needs.security-tests.result }}" != "success" ]; then
                FAILED_JOBS+=("$job")
              fi
              ;;
            "performance-tests")
              if [ "${{ needs.performance-tests.result }}" != "success" ]; then
                FAILED_JOBS+=("$job")
              fi
              ;;
            "e2e-tests")
              if [ "${{ needs.e2e-tests.result }}" != "success" ]; then
                FAILED_JOBS+=("$job")
              fi
              ;;
            "webhook-tests")
              if [ "${{ needs.webhook-tests.result }}" != "success" ]; then
                FAILED_JOBS+=("$job")
              fi
              ;;
            "monitoring-validation")
              if [ "${{ needs.monitoring-validation.result }}" != "success" ]; then
                FAILED_JOBS+=("$job")
              fi
              ;;
          esac
        done
        
        if [ ${#FAILED_JOBS[@]} -eq 0 ]; then
          echo "‚úÖ All unified quality gates passed!"
          echo "üöÄ Ready for deployment"
        else
          echo "‚ùå Unified quality gate failed!"
          echo "Failed jobs: ${FAILED_JOBS[*]}"
          exit 1
        fi
        
    - name: Post quality gate results
      if: always()
      run: |
        echo "## Unified Quality Gate Results" >> $GITHUB_STEP_SUMMARY
        echo "| Test Suite | Status |" >> $GITHUB_STEP_SUMMARY
        echo "|------------|--------|" >> $GITHUB_STEP_SUMMARY
        echo "| Unit Tests | ${{ needs.unit-tests.result == 'success' && '‚úÖ Passed' || '‚ùå Failed' }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Integration Tests | ${{ needs.integration-tests.result == 'success' && '‚úÖ Passed' || '‚ùå Failed' }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Security Tests | ${{ needs.security-tests.result == 'success' && '‚úÖ Passed' || '‚ùå Failed' }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Performance Tests | ${{ needs.performance-tests.result == 'success' && '‚úÖ Passed' || '‚ùå Failed' }} |" >> $GITHUB_STEP_SUMMARY
        echo "| E2E Tests | ${{ needs.e2e-tests.result == 'success' && '‚úÖ Passed' || '‚ùå Failed' }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Webhook Tests | ${{ needs.webhook-tests.result == 'success' && '‚úÖ Passed' || '‚ùå Failed' }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Monitoring Validation | ${{ needs.monitoring-validation.result == 'success' && '‚úÖ Passed' || '‚ùå Failed' }} |" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### Consolidation Achievement" >> $GITHUB_STEP_SUMMARY
        echo "- ‚úÖ **5 PRs ‚Üí 1 System**: Successfully consolidated PRs #51, #67, #71, #72, #94" >> $GITHUB_STEP_SUMMARY
        echo "- ‚úÖ **Zero Redundancy**: Eliminated all duplicate code and functionality" >> $GITHUB_STEP_SUMMARY
        echo "- ‚úÖ **Unified Testing**: Single comprehensive testing framework" >> $GITHUB_STEP_SUMMARY
        echo "- ‚úÖ **Unified Monitoring**: Single comprehensive monitoring system" >> $GITHUB_STEP_SUMMARY
        echo "- ‚úÖ **Unified Configuration**: Single configuration management system" >> $GITHUB_STEP_SUMMARY
        echo "- ‚úÖ **Feature Preservation**: 100% functionality preserved from all source PRs" >> $GITHUB_STEP_SUMMARY

